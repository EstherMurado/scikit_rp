{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27618b09-32d3-4f52-a96b-d1ec5940caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================\n",
    "OOB Errors for Random Forests\n",
    "=============================\n",
    "\n",
    "The ``RandomForestClassifier`` is trained using *bootstrap aggregation*, where\n",
    "each new tree is fit from a bootstrap sample of the training observations\n",
    ":math:`z_i = (x_i, y_i)`. The *out-of-bag* (OOB) error is the average error for\n",
    "each :math:`z_i` calculated using predictions from the trees that do not\n",
    "contain :math:`z_i` in their respective bootstrap sample. This allows the\n",
    "``RandomForestClassifier`` to be fit and validated whilst being trained [1]_.\n",
    "\n",
    "The example below demonstrates how the OOB error can be measured at the\n",
    "addition of each new tree during training. The resulting plot allows a\n",
    "practitioner to approximate a suitable value of ``n_estimators`` at which the\n",
    "error stabilizes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a7faa-789c-4ae4-95e0-fb5e9d7a81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f5bd8-84e0-4637-b23b-37ffb496a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cuando se trabaja con algoritmos de aprendizaje automático que implican aleatoriedad, como entrenar un modelo \n",
    "de Bosques Aleatorios, hay que tener en cuenta que los resultados pueden variar dependiendo de la semilla aleatoria que usemos. \n",
    "La semilla aleatoria determina la secuencia de números pseudoaleatorios generados por el algoritmo.\n",
    "\n",
    "Al establecer una semilla aleatoria específica, se asegura que los resultados sean reproducibles, es decir, \n",
    "que al ejecutar el código varias veces con la misma semilla aleatoria, se obtendrán los mismos resultados cada vez. \n",
    "Esto es útil para fines de depuración, experimentación y comparación de modelos.\n",
    "\n",
    "Esto garantiza que, si el código se ejecuta varias veces con la misma semilla aleatoria, se obtendrán los mismos \n",
    "resultados en cada ejecución, lo que facilita la reproducibilidad de los experimentos y los resultados del modelo.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" \n",
    "Se define una semilla aleatoria (RANDOM_STATE) para reproducibilidad. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ff645-fd5b-4408-a68c-2a4b2f6aaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "# se utiliza para asegurar que se obtenga el mismo conjunto de datos si se ejecuta el código varias veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f435c4c-4b02-48a7-af9c-1bd428c4e138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9e4bb-6b40-4224-9e40-fd16bbbf80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Se genera un conjunto de datos de clasificación binaria utilizando make_classification de scikit-learn. \n",
    "\n",
    "La función make_classification devuelve dos matrices NumPy: 'X', que contiene las características de las muestras generadas, \n",
    "e 'y', que contiene las etiquetas de clase asociadas a cada muestra. \n",
    "\"\"\"\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=500,  # número total de muestras\n",
    "    n_features=25,  # número de características (o variables) que tendrá cada muestra\n",
    "    n_clusters_per_class=1,   # número de clústeres por clase. Hace que las muestras de cada clase se agrupen en un solo grupo.\n",
    "    n_informative=15,  # número de características que son relevantes (informativas) para predecir la variable objetivo\n",
    "                       # De las 25 características totales, 15 serán informativas,\n",
    "    random_state=RANDOM_STATE,  # establece la semilla aleatoria para generar el conjunto de datos.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ad3a1-50cc-42b5-aa8a-ec6f2bff5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se definen diferentes configuraciones de RandomForestClassifier con diferentes valores \n",
    "para el parámetro max_features y se almacenan en una lista llamada ensemble_clfs.\n",
    "\"\"\"\n",
    "\n",
    "ensemble_clfs = [\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=\"log2\",\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features=None\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            max_features=None,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db829806-f15e-44fc-b066-db04e9cd1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7035b4e-d8da-4305-9c05-3a3484af4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features --> especifica cómo se seleccionan las características aleatorias\n",
    "\n",
    "# none -> (valor predeterminado), todas las características se considerarán para cada división en cada nodo del árbol. \n",
    "# sqrt -> el modelo considerará la raíz cuadrada del número total de características (25) en el conjunto de datos para cada división.\n",
    "# log2 -> el modelo considerará el logaritmo base 2 del número total de características en el conjunto de datos para cada división.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d9baf-851b-4a55-94af-be8c1cc80e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuando oob_score = True, el modelo de Bosques Aleatorios calculará automáticamente el puntaje de error fuera \n",
    "# de la bolsa después del entrenamiento. \n",
    "# Este puntaje OOB proporciona una estimación del rendimiento del modelo en datos no vistos \n",
    "# sin necesidad de un conjunto de validación separado.\n",
    "\n",
    "# Al establecer oob_score=True, se calcula y se proporciona un puntaje de error fuera de la bolsa \n",
    "# después del entrenamiento del modelo de Bosques Aleatorios, lo que puede ser útil para evaluar su rendimiento de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae6d8b-2cde-4b5f-86f6-fb07f6853513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Se crea un diccionario llamado error_rate que mapea el nombre del clasificador a una lista vacía. \n",
    "Esta lista almacenará las tasas de error fuera de la bolsa (OOB) para cada configuración de clasificador. \n",
    "\"\"\"\n",
    "\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "# Mapea un name classificador a una lista de (<n_estimators>, <error rate>) pares.\n",
    "# orderedDict -> Dictionary that remembers insertion order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2620bb0-8c27-4fd7-8b47-c5dcf7383503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "crea un diccionario llamado error_rate, donde las claves son los nombres de los clasificadores y los valores son listas vacías. \n",
    "    · orderedDict -> Dictionary that remembers insertion order\n",
    "    · (label, []): Aquí, para cada elemento en ensemble_clfs, estamos creando una tupla que consta de dos partes:\n",
    "        label: Es el nombre del clasificador en ensemble_clfs.\n",
    "        []: Es una lista vacía.\n",
    "    · for label, _ in ensemble_clfs: Esto itera sobre cada elemento en ensemble_clfs, que es una lista de tuplas donde \n",
    "    cada tupla contiene el nombre de un clasificador y el clasificador mismo. El _ se utiliza para ignorar la parte \n",
    "    del clasificador en cada tupla, ya que en este caso solo estamos interesados en los nombres.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16bab99-cb00-4f39-a1d3-0538fc18ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define un rango de valores para n_estimators que se explorarán\n",
    "min_estimators = 15\n",
    "max_estimators = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4213f-2d4c-4942-9a69-02a09be44cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de45de-530b-47cd-b85c-fe91f1b55981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, clf in ensemble_clfs:  # Iteración sobre ensemble_clfs\n",
    "    for i in range(min_estimators, max_estimators + 1, 5):  # Iteración sobre el rango de estimadores\n",
    "# Estamos iterando sobre un rango de estimadores. Comenzamos desde min_estimators y vamos en incrementos de 5 hasta max_estimators.\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03043697-729e-4598-a03a-1d02e864604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "label -> nombre clasificador\n",
    "clf -> clasificador\n",
    "Ajustamos (fit()) el clasificador al conjunto de datos de entrenamiento (X, y). \n",
    "Esto significa que estamos entrenando el clasificador con un número específico de estimadores en cada iteración.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ffae9-b3e0-45f7-a62d-682069926e46",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Cálculo del error fuera de la bolsa (OOB):\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "    # Almacenamiento del error OOB en error_rate:\n",
    "        error_rate[label].append((i, oob_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eac98b-20d4-4ddd-9d48-5ee7f4335f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Una vez que el clasificador está ajustado, calculamos el error fuera de la bolsa (OOB) \n",
    "utilizando el atributo oob_score_ del clasificador. Este atributo proporciona la puntuación OOB del modelo, \n",
    "que es una medida de su rendimiento en datos no vistos.\n",
    "\n",
    "Finalmente, almacenamos el error OOB para el clasificador actual en el diccionario error_rate. \n",
    "El error OOB se almacena como una tupla (n_estimators, oob_error) dentro de una lista asociada con la \n",
    "etiqueta del clasificador en el diccionario error_rate.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88236325-d984-4d90-8ccd-785da17d58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee35a8b5-364b-4126-9ea3-9e9f040b10eb",
   "metadata": {},
   "source": [
    "for label, clf_err in error_rate.items() --> Iteramos sobre el diccionario error rate\n",
    "Cada elemento consiste en una clave (label) que representa el nombre del clasificador y un valor (clf_err) \n",
    "que es una lista de tuplas que contiene los valores (n_estimators, oob_error) para ese clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7193ea9-af2b-45a7-aa37-238ec21fd4e1",
   "metadata": {},
   "source": [
    " xs, ys = zip(*clf_err) --> Desempaquetado de las listas de tuplas:\n",
    "La función zip(*clf_err) toma la lista de tuplas clf_err y la desempaqueta en dos listas separadas xs y ys. Esto significa que xs contendrá todos los valores de n_estimators y ys contendrá todos los valores de oob_error para el clasificador actual.\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f4f7658-8be5-4008-8e8b-b50d5a27b73a",
   "metadata": {},
   "source": [
    "plt.plot(xs, ys, label=label) -->  Trama del gráfico de líneas:\n",
    "Usando plt.plot, estamos trazando un gráfico de líneas donde los valores de n_estimators se colocan en el eje x y los valores de oob_error se colocan en el eje y. Cada línea en el gráfico representa la relación entre el número de estimadores y el error fuera de la bolsa (OOB) para un clasificador específico. La etiqueta label se utiliza para identificar cada línea en la leyenda del gráfico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
